#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
HVDC Warehouse ì¢…í•© ë¦¬ë“œíƒ€ì„ ë¶„ì„ ì‹œìŠ¤í…œ
- ì „ì²´ Caseë¥¼ ë¹ ì§ì—†ì´ í¬í•¨ (ë¯¸ì¶œê³ , ë¯¸ì…ê³  í¬í•¨)
- Caseë³„ ìƒíƒœ ë¶„ë¥˜ (ì¶œê³ ì™„ë£Œ/ë¯¸ì¶œê³ /ë¯¸ì…ê³ )
- ì‹¤ë¬´ì—ì„œ ë°”ë¡œ ì‚¬ìš© ê°€ëŠ¥í•œ ì—‘ì…€ ë¦¬í¬íŠ¸
"""

import os
import sys
import pandas as pd
import numpy as np
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

class ComprehensiveLeadtimeAnalyzer:
    """ì¢…í•© ë¦¬ë“œíƒ€ì„ ë¶„ì„ í´ë˜ìŠ¤"""
    
    def __init__(self, excel_path, sheet_name='CASE LIST'):
        """
        ì¢…í•© ë¦¬ë“œíƒ€ì„ ë¶„ì„ê¸° ì´ˆê¸°í™”
        
        Args:
            excel_path: ì—‘ì…€ íŒŒì¼ ê²½ë¡œ
            sheet_name: ì‹œíŠ¸ ì´ë¦„
        """
        self.excel_path = excel_path
        self.sheet_name = sheet_name
        self.df = None
        self.warehouse_cols = []
        self.site_cols = []
        
        self._load_data()
        self._identify_columns()
    
    def _load_data(self):
        """ë°ì´í„° ë¡œë“œ"""
        print(f"ğŸ“ ë°ì´í„° íŒŒì¼ ë¡œë“œ ì¤‘: {self.excel_path}")
        self.df = pd.read_excel(self.excel_path, sheet_name=self.sheet_name)
        print(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(self.df)}í–‰")
    
    def _identify_columns(self):
        """ì…ê³ /ì¶œê³  ì»¬ëŸ¼ ì‹ë³„"""
        # ì…ê³  ì»¬ëŸ¼ (ì°½ê³ ) ì‹ë³„
        warehouse_patterns = ['DSV', 'Hauler', 'MOSB']
        self.warehouse_cols = []
        for col in self.df.columns:
            if any(pattern in str(col) for pattern in warehouse_patterns):
                self.warehouse_cols.append(col)
        
        # ì¶œê³  ì»¬ëŸ¼ (í˜„ì¥) ì‹ë³„
        site_patterns = ['MIR', 'SHU', 'DAS', 'AGI']
        self.site_cols = []
        for col in self.df.columns:
            if any(pattern in str(col) for pattern in site_patterns):
                self.site_cols.append(col)
        
        print(f"ğŸ­ ì…ê³  ì»¬ëŸ¼ ({len(self.warehouse_cols)}ê°œ): {self.warehouse_cols}")
        print(f"ğŸ—ï¸  ì¶œê³  ì»¬ëŸ¼ ({len(self.site_cols)}ê°œ): {self.site_cols}")
    
    def calculate_comprehensive_leadtime(self):
        """
        ì¢…í•© ë¦¬ë“œíƒ€ì„ ê³„ì‚° (ì „ì²´ Case í¬í•¨)
        
        Returns:
            DataFrame: ëª¨ë“  Caseê°€ í¬í•¨ëœ ë¦¬ë“œíƒ€ì„ DataFrame
        """
        print("\nğŸ“Š ì¢…í•© ë¦¬ë“œíƒ€ì„ ê³„ì‚° ì¤‘...")
        
        # 1) ë‚ ì§œ ì»¬ëŸ¼ë“¤ì„ datetimeìœ¼ë¡œ ë³€í™˜
        date_cols = self.warehouse_cols + self.site_cols
        for col in date_cols:
            if col in self.df.columns:
                self.df[col] = pd.to_datetime(self.df[col], errors='coerce')
        
        # 2) ì…ê³ ì¼ ê³„ì‚° (ê° Caseì˜ ëª¨ë“  ì…ê³  ì°½ê³  ì¼ì ì¤‘ ê°€ì¥ ì´ë¥¸ ë‚ ì§œ)
        print("  ğŸ“… ì…ê³ ì¼ ê³„ì‚° ì¤‘...")
        self.df['ì…ê³ ì¼'] = self.df[self.warehouse_cols].min(axis=1)
        
        # 3) ì¶œê³ ì¼ ê³„ì‚° (ê° Caseì˜ ëª¨ë“  ì¶œê³  í˜„ì¥ ì¼ì ì¤‘ ê°€ì¥ ëŠ¦ì€ ë‚ ì§œ)
        print("  ğŸ“… ì¶œê³ ì¼ ê³„ì‚° ì¤‘...")
        self.df['ì¶œê³ ì¼'] = self.df[self.site_cols].max(axis=1)
        
        # 4) ë¦¬ë“œíƒ€ì„(ì¼) ê³„ì‚° (ì¶œê³ ì™„ë£Œëœ Caseë§Œ)
        print("  â±ï¸  ë¦¬ë“œíƒ€ì„ ê³„ì‚° ì¤‘...")
        self.df['ë¦¬ë“œíƒ€ì„(ì¼)'] = (self.df['ì¶œê³ ì¼'] - self.df['ì…ê³ ì¼']).dt.days
        
        # 5) ì´ˆê¸° ì…ê³  ì°½ê³ ëª… ì‹ë³„
        print("  ğŸ­ ì´ˆê¸° ì…ê³  ì°½ê³  ì‹ë³„ ì¤‘...")
        self.df['ì´ˆê¸°ì°½ê³ '] = None
        for idx, row in self.df.iterrows():
            warehouse_dates = row[self.warehouse_cols]
            valid_dates = warehouse_dates.dropna()
            if len(valid_dates) > 0:
                min_date_idx = valid_dates.idxmin()
                self.df.at[idx, 'ì´ˆê¸°ì°½ê³ '] = min_date_idx
        
        # 6) Case ìƒíƒœ ë¶„ë¥˜
        print("  ğŸ“‹ Case ìƒíƒœ ë¶„ë¥˜ ì¤‘...")
        self.df['ìƒíƒœ'] = self.df.apply(self._classify_case_status, axis=1)
        
        # 7) í˜„ì¬ ì²´ë¥˜ì¼ìˆ˜ ê³„ì‚° (ë¯¸ì¶œê³  Caseìš©)
        print("  ğŸ“… í˜„ì¬ ì²´ë¥˜ì¼ìˆ˜ ê³„ì‚° ì¤‘...")
        today = pd.Timestamp.now()
        self.df['í˜„ì¬ì²´ë¥˜ì¼ìˆ˜'] = (today - self.df['ì…ê³ ì¼']).dt.days
        
        print(f"âœ… ì¢…í•© ë¦¬ë“œíƒ€ì„ ê³„ì‚° ì™„ë£Œ!")
        print(f"  ğŸ“Š ì´ Case ìˆ˜: {len(self.df)}")
        
        # ìƒíƒœë³„ í†µê³„ ì¶œë ¥
        status_counts = self.df['ìƒíƒœ'].value_counts()
        print(f"  ğŸ“Š ìƒíƒœë³„ ë¶„í¬:")
        for status, count in status_counts.items():
            print(f"    - {status}: {count}ê±´")
        
        return self.df
    
    def _classify_case_status(self, row):
        """Case ìƒíƒœ ë¶„ë¥˜"""
        if pd.isna(row['ì…ê³ ì¼']):
            return "ë¯¸ì…ê³ "
        elif pd.isna(row['ì¶œê³ ì¼']):
            return "ë¯¸ì¶œê³ "
        else:
            return "ì¶œê³ ì™„ë£Œ"
    
    def analyze_by_status(self):
        """
        ìƒíƒœë³„ ë¦¬ë“œíƒ€ì„ í†µê³„ ë¶„ì„
        
        Returns:
            dict: ìƒíƒœë³„ í†µê³„ ë°ì´í„°
        """
        print("\nğŸ“Š ìƒíƒœë³„ ë¶„ì„ ì¤‘...")
        
        # ì¶œê³ ì™„ë£Œ Caseë§Œ í•„í„°ë§
        completed_cases = self.df[self.df['ìƒíƒœ'] == 'ì¶œê³ ì™„ë£Œ'].copy()
        
        if len(completed_cases) > 0:
            print(f"  ğŸ“Š ì¶œê³ ì™„ë£Œ Case: {len(completed_cases)}ê±´")
            print(f"    - í‰ê·  ë¦¬ë“œíƒ€ì„: {completed_cases['ë¦¬ë“œíƒ€ì„(ì¼)'].mean():.1f}ì¼")
            print(f"    - ì¤‘ì•™ê°’ ë¦¬ë“œíƒ€ì„: {completed_cases['ë¦¬ë“œíƒ€ì„(ì¼)'].median():.1f}ì¼")
            print(f"    - ìµœëŒ“ê°’ ë¦¬ë“œíƒ€ì„: {completed_cases['ë¦¬ë“œíƒ€ì„(ì¼)'].max():.0f}ì¼")
        
        # ë¯¸ì¶œê³  Case ë¶„ì„
        pending_cases = self.df[self.df['ìƒíƒœ'] == 'ë¯¸ì¶œê³ '].copy()
        if len(pending_cases) > 0:
            print(f"  ğŸ“Š ë¯¸ì¶œê³  Case: {len(pending_cases)}ê±´")
            print(f"    - í‰ê·  ì²´ë¥˜ì¼ìˆ˜: {pending_cases['í˜„ì¬ì²´ë¥˜ì¼ìˆ˜'].mean():.1f}ì¼")
            print(f"    - ì¤‘ì•™ê°’ ì²´ë¥˜ì¼ìˆ˜: {pending_cases['í˜„ì¬ì²´ë¥˜ì¼ìˆ˜'].median():.1f}ì¼")
            print(f"    - ìµœëŒ“ê°’ ì²´ë¥˜ì¼ìˆ˜: {pending_cases['í˜„ì¬ì²´ë¥˜ì¼ìˆ˜'].max():.0f}ì¼")
        
        return {
            'completed': completed_cases,
            'pending': pending_cases,
            'no_inbound': self.df[self.df['ìƒíƒœ'] == 'ë¯¸ì…ê³ ']
        }
    
    def analyze_by_warehouse(self):
        """
        ì°½ê³ ë³„ ë¦¬ë“œíƒ€ì„ í†µê³„ ë¶„ì„ (ì¶œê³ ì™„ë£Œ Caseë§Œ)
        
        Returns:
            DataFrame: ì°½ê³ ë³„ ë¦¬ë“œíƒ€ì„ í†µê³„
        """
        print("\nğŸ­ ì°½ê³ ë³„ ë¦¬ë“œíƒ€ì„ ë¶„ì„ ì¤‘...")
        
        completed_cases = self.df[self.df['ìƒíƒœ'] == 'ì¶œê³ ì™„ë£Œ'].copy()
        
        if len(completed_cases) == 0:
            print("  âš ï¸  ì¶œê³ ì™„ë£Œëœ Caseê°€ ì—†ìŠµë‹ˆë‹¤.")
            return pd.DataFrame()
        
        warehouse_stats = completed_cases.groupby('ì´ˆê¸°ì°½ê³ ')['ë¦¬ë“œíƒ€ì„(ì¼)'].agg([
            'count', 'mean', 'median', 'std', 'min', 'max'
        ]).reset_index()
        warehouse_stats.columns = ['ì°½ê³ ', 'ê±´ìˆ˜', 'í‰ê· (ì¼)', 'ì¤‘ì•™ê°’(ì¼)', 'í‘œì¤€í¸ì°¨', 'ìµœì†Ÿê°’(ì¼)', 'ìµœëŒ“ê°’(ì¼)']
        
        # ì†Œìˆ˜ì  ì •ë¦¬
        numeric_cols = warehouse_stats.select_dtypes(include=[np.number]).columns
        warehouse_stats[numeric_cols] = warehouse_stats[numeric_cols].round(1)
        
        print(f"âœ… ì°½ê³ ë³„ ë¶„ì„ ì™„ë£Œ: {len(warehouse_stats)}ê°œ ì°½ê³ ")
        return warehouse_stats
    
    def get_dead_stock_cases(self, threshold_days=90):
        """
        Dead Stock Case ëª©ë¡ ì¡°íšŒ (ë¯¸ì¶œê³  + ì²´ë¥˜ì¼ìˆ˜ ì„ê³„ê°’ ì´ˆê³¼)
        
        Args:
            threshold_days: ì„ê³„ê°’ (ì¼)
            
        Returns:
            DataFrame: Dead Stock Case ëª©ë¡
        """
        print(f"\nâ° Dead Stock Case ë¶„ì„ (ì„ê³„ê°’: {threshold_days}ì¼)...")
        
        dead_stock = self.df[
            (self.df['ìƒíƒœ'] == 'ë¯¸ì¶œê³ ') & 
            (self.df['í˜„ì¬ì²´ë¥˜ì¼ìˆ˜'] >= threshold_days)
        ].copy()
        dead_stock = dead_stock.sort_values('í˜„ì¬ì²´ë¥˜ì¼ìˆ˜', ascending=False)
        
        print(f"âœ… Dead Stock Case: {len(dead_stock)}ê±´")
        return dead_stock
    
    def get_long_leadtime_cases(self, threshold_days=90):
        """
        ê¸´ ë¦¬ë“œíƒ€ì„ Case ëª©ë¡ ì¡°íšŒ (ì¶œê³ ì™„ë£Œ Caseë§Œ)
        
        Args:
            threshold_days: ì„ê³„ê°’ (ì¼)
            
        Returns:
            DataFrame: ê¸´ ë¦¬ë“œíƒ€ì„ Case ëª©ë¡
        """
        print(f"\nâ° ê¸´ ë¦¬ë“œíƒ€ì„ Case ë¶„ì„ (ì„ê³„ê°’: {threshold_days}ì¼)...")
        
        long_leadtime = self.df[
            (self.df['ìƒíƒœ'] == 'ì¶œê³ ì™„ë£Œ') & 
            (self.df['ë¦¬ë“œíƒ€ì„(ì¼)'] >= threshold_days)
        ].copy()
        long_leadtime = long_leadtime.sort_values('ë¦¬ë“œíƒ€ì„(ì¼)', ascending=False)
        
        print(f"âœ… ê¸´ ë¦¬ë“œíƒ€ì„ Case: {len(long_leadtime)}ê±´")
        return long_leadtime
    
    def generate_comprehensive_report(self, output_file=None):
        """
        ì¢…í•© ë¦¬ë“œíƒ€ì„ ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±
        
        Args:
            output_file: ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
            
        Returns:
            str: ìƒì„±ëœ íŒŒì¼ ê²½ë¡œ
        """
        print("\nğŸ“‹ ì¢…í•© ë¦¬ë“œíƒ€ì„ ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„± ì¤‘...")
        
        if output_file is None:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            output_dir = os.path.join(os.path.dirname(__file__), 'outputs')
            os.makedirs(output_dir, exist_ok=True)
            output_file = os.path.join(output_dir, f'ì¢…í•©_ë¦¬ë“œíƒ€ì„_ë¶„ì„_{timestamp}.xlsx')
        
        with pd.ExcelWriter(output_file, engine='openpyxl') as writer:
            # 1. ì „ì²´ Case ë¦¬ë“œíƒ€ì„ ë°ì´í„° (ëª¨ë“  Case í¬í•¨)
            print("  ğŸ“‹ ì „ì²´ Case ë¦¬ë“œíƒ€ì„ ë°ì´í„° ì €ì¥ ì¤‘...")
            display_cols = ['Case No.', 'ì´ˆê¸°ì°½ê³ ', 'ì…ê³ ì¼', 'ì¶œê³ ì¼', 'ë¦¬ë“œíƒ€ì„(ì¼)', 'í˜„ì¬ì²´ë¥˜ì¼ìˆ˜', 'ìƒíƒœ']
            self.df[display_cols].to_excel(writer, sheet_name='ì „ì²´_Case_ë¦¬ë“œíƒ€ì„', index=False)
            
            # 2. ìƒíƒœë³„ Case ëª©ë¡
            print("  ğŸ“‹ ìƒíƒœë³„ Case ëª©ë¡ ì €ì¥ ì¤‘...")
            status_analysis = self.analyze_by_status()
            
            # ì¶œê³ ì™„ë£Œ Case
            if len(status_analysis['completed']) > 0:
                completed_cols = ['Case No.', 'ì´ˆê¸°ì°½ê³ ', 'ì…ê³ ì¼', 'ì¶œê³ ì¼', 'ë¦¬ë“œíƒ€ì„(ì¼)']
                status_analysis['completed'][completed_cols].to_excel(writer, sheet_name='ì¶œê³ ì™„ë£Œ_Case', index=False)
            
            # ë¯¸ì¶œê³  Case
            if len(status_analysis['pending']) > 0:
                pending_cols = ['Case No.', 'ì´ˆê¸°ì°½ê³ ', 'ì…ê³ ì¼', 'í˜„ì¬ì²´ë¥˜ì¼ìˆ˜']
                status_analysis['pending'][pending_cols].to_excel(writer, sheet_name='ë¯¸ì¶œê³ _Case', index=False)
            
            # ë¯¸ì…ê³  Case
            if len(status_analysis['no_inbound']) > 0:
                no_inbound_cols = ['Case No.', 'ì´ˆê¸°ì°½ê³ ']
                status_analysis['no_inbound'][no_inbound_cols].to_excel(writer, sheet_name='ë¯¸ì…ê³ _Case', index=False)
            
            # 3. ì°½ê³ ë³„ í†µê³„
            print("  ğŸ“‹ ì°½ê³ ë³„ í†µê³„ ì €ì¥ ì¤‘...")
            warehouse_stats = self.analyze_by_warehouse()
            if len(warehouse_stats) > 0:
                warehouse_stats.to_excel(writer, sheet_name='ì°½ê³ ë³„_ë¦¬ë“œíƒ€ì„_í†µê³„', index=False)
            
            # 4. Dead Stock Case ëª©ë¡
            print("  ğŸ“‹ Dead Stock Case ëª©ë¡ ì €ì¥ ì¤‘...")
            dead_stock = self.get_dead_stock_cases(90)
            if len(dead_stock) > 0:
                dead_stock_cols = ['Case No.', 'ì´ˆê¸°ì°½ê³ ', 'ì…ê³ ì¼', 'í˜„ì¬ì²´ë¥˜ì¼ìˆ˜']
                dead_stock[dead_stock_cols].to_excel(writer, sheet_name='DeadStock_90ì¼+', index=False)
            
            # 5. ê¸´ ë¦¬ë“œíƒ€ì„ Case ëª©ë¡
            print("  ğŸ“‹ ê¸´ ë¦¬ë“œíƒ€ì„ Case ëª©ë¡ ì €ì¥ ì¤‘...")
            long_leadtime = self.get_long_leadtime_cases(90)
            if len(long_leadtime) > 0:
                long_leadtime_cols = ['Case No.', 'ì´ˆê¸°ì°½ê³ ', 'ì…ê³ ì¼', 'ì¶œê³ ì¼', 'ë¦¬ë“œíƒ€ì„(ì¼)']
                long_leadtime[long_leadtime_cols].to_excel(writer, sheet_name='ê¸´ë¦¬ë“œíƒ€ì„_90ì¼+', index=False)
            
            # 6. ì¢…í•© ìš”ì•½ ì •ë³´
            print("  ğŸ“‹ ì¢…í•© ìš”ì•½ ì •ë³´ ì €ì¥ ì¤‘...")
            summary_data = {
                'ë¶„ì„ í•­ëª©': [
                    'ì´ Case ìˆ˜',
                    'ì¶œê³ ì™„ë£Œ Case ìˆ˜',
                    'ë¯¸ì¶œê³  Case ìˆ˜',
                    'ë¯¸ì…ê³  Case ìˆ˜',
                    'ì¶œê³ ì™„ë£Œ Case í‰ê·  ë¦¬ë“œíƒ€ì„(ì¼)',
                    'ì¶œê³ ì™„ë£Œ Case ì¤‘ì•™ê°’ ë¦¬ë“œíƒ€ì„(ì¼)',
                    'ì¶œê³ ì™„ë£Œ Case ìµœëŒ“ê°’ ë¦¬ë“œíƒ€ì„(ì¼)',
                    'ë¯¸ì¶œê³  Case í‰ê·  ì²´ë¥˜ì¼ìˆ˜',
                    'ë¯¸ì¶œê³  Case ì¤‘ì•™ê°’ ì²´ë¥˜ì¼ìˆ˜',
                    'ë¯¸ì¶œê³  Case ìµœëŒ“ê°’ ì²´ë¥˜ì¼ìˆ˜',
                    '90ì¼ ì´ìƒ ë¦¬ë“œíƒ€ì„ Case ìˆ˜',
                    '90ì¼ ì´ìƒ ì²´ë¥˜ ë¯¸ì¶œê³  Case ìˆ˜ (Dead Stock)',
                    'ë¶„ì„ ì°½ê³  ìˆ˜'
                ],
                'ê°’': [
                    len(self.df),
                    len(self.df[self.df['ìƒíƒœ'] == 'ì¶œê³ ì™„ë£Œ']),
                    len(self.df[self.df['ìƒíƒœ'] == 'ë¯¸ì¶œê³ ']),
                    len(self.df[self.df['ìƒíƒœ'] == 'ë¯¸ì…ê³ ']),
                    round(self.df[self.df['ìƒíƒœ'] == 'ì¶œê³ ì™„ë£Œ']['ë¦¬ë“œíƒ€ì„(ì¼)'].mean(), 1) if len(self.df[self.df['ìƒíƒœ'] == 'ì¶œê³ ì™„ë£Œ']) > 0 else 0,
                    round(self.df[self.df['ìƒíƒœ'] == 'ì¶œê³ ì™„ë£Œ']['ë¦¬ë“œíƒ€ì„(ì¼)'].median(), 1) if len(self.df[self.df['ìƒíƒœ'] == 'ì¶œê³ ì™„ë£Œ']) > 0 else 0,
                    self.df[self.df['ìƒíƒœ'] == 'ì¶œê³ ì™„ë£Œ']['ë¦¬ë“œíƒ€ì„(ì¼)'].max() if len(self.df[self.df['ìƒíƒœ'] == 'ì¶œê³ ì™„ë£Œ']) > 0 else 0,
                    round(self.df[self.df['ìƒíƒœ'] == 'ë¯¸ì¶œê³ ']['í˜„ì¬ì²´ë¥˜ì¼ìˆ˜'].mean(), 1) if len(self.df[self.df['ìƒíƒœ'] == 'ë¯¸ì¶œê³ ']) > 0 else 0,
                    round(self.df[self.df['ìƒíƒœ'] == 'ë¯¸ì¶œê³ ']['í˜„ì¬ì²´ë¥˜ì¼ìˆ˜'].median(), 1) if len(self.df[self.df['ìƒíƒœ'] == 'ë¯¸ì¶œê³ ']) > 0 else 0,
                    self.df[self.df['ìƒíƒœ'] == 'ë¯¸ì¶œê³ ']['í˜„ì¬ì²´ë¥˜ì¼ìˆ˜'].max() if len(self.df[self.df['ìƒíƒœ'] == 'ë¯¸ì¶œê³ ']) > 0 else 0,
                    len(self.get_long_leadtime_cases(90)),
                    len(self.get_dead_stock_cases(90)),
                    len(self.df['ì´ˆê¸°ì°½ê³ '].dropna().unique())
                ]
            }
            summary_df = pd.DataFrame(summary_data)
            summary_df.to_excel(writer, sheet_name='ì¢…í•©_ë¶„ì„_ìš”ì•½', index=False)
        
        print(f"âœ… ì¢…í•© ë¦¬ë“œíƒ€ì„ ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ!")
        print(f"ğŸ“„ íŒŒì¼ëª…: {os.path.basename(output_file)}")
        print(f"ğŸ“„ íŒŒì¼ í¬ê¸°: {os.path.getsize(output_file) / 1024:.1f} KB")
        
        return output_file

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("=== HVDC Warehouse ì¢…í•© ë¦¬ë“œíƒ€ì„ ë¶„ì„ ì‹œìŠ¤í…œ ===")
    print(f"ì‹¤í–‰ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # 1. ë°ì´í„° íŒŒì¼ ê²½ë¡œ ì„¤ì •
    current_dir = os.path.dirname(os.path.abspath(__file__))
    excel_path = os.path.join(current_dir, 'data', 'HVDC WAREHOUSE_HITACHI(HE).xlsx')
    
    if not os.path.exists(excel_path):
        print(f"âŒ ì˜¤ë¥˜: ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {excel_path}")
        return
    
    try:
        # 2. ì¢…í•© ë¦¬ë“œíƒ€ì„ ë¶„ì„ê¸° ì´ˆê¸°í™”
        print(f"\nğŸ“ ë°ì´í„° íŒŒì¼: {excel_path}")
        analyzer = ComprehensiveLeadtimeAnalyzer(excel_path, sheet_name='CASE LIST')
        
        # 3. ì¢…í•© ë¦¬ë“œíƒ€ì„ ê³„ì‚°
        df_comprehensive = analyzer.calculate_comprehensive_leadtime()
        
        # 4. ìƒì„¸ ë¶„ì„
        print("\nğŸ“Š ìƒì„¸ ë¶„ì„ ê²°ê³¼:")
        
        # ìƒíƒœë³„ ë¶„ì„
        status_analysis = analyzer.analyze_by_status()
        
        # ì°½ê³ ë³„ ë¶„ì„
        warehouse_stats = analyzer.analyze_by_warehouse()
        if len(warehouse_stats) > 0:
            print(f"\nğŸ­ ì°½ê³ ë³„ ë¦¬ë“œíƒ€ì„ í†µê³„ (ì¶œê³ ì™„ë£Œ Caseë§Œ):")
            print(warehouse_stats.to_string(index=False))
        
        # Dead Stock ë¶„ì„
        dead_stock = analyzer.get_dead_stock_cases(90)
        print(f"\nâ° Dead Stock Case (90ì¼ ì´ìƒ ì²´ë¥˜, ìƒìœ„ 10ê±´):")
        if len(dead_stock) > 0:
            display_cols = ['Case No.', 'ì´ˆê¸°ì°½ê³ ', 'ì…ê³ ì¼', 'í˜„ì¬ì²´ë¥˜ì¼ìˆ˜']
            print(dead_stock[display_cols].head(10).to_string(index=False))
        
        # ê¸´ ë¦¬ë“œíƒ€ì„ ë¶„ì„
        long_leadtime = analyzer.get_long_leadtime_cases(90)
        print(f"\nâ° ê¸´ ë¦¬ë“œíƒ€ì„ Case (90ì¼ ì´ìƒ, ìƒìœ„ 10ê±´):")
        if len(long_leadtime) > 0:
            display_cols = ['Case No.', 'ì´ˆê¸°ì°½ê³ ', 'ì…ê³ ì¼', 'ì¶œê³ ì¼', 'ë¦¬ë“œíƒ€ì„(ì¼)']
            print(long_leadtime[display_cols].head(10).to_string(index=False))
        
        # 5. ì¢…í•© ì—‘ì…€ ë¦¬í¬íŠ¸ ìƒì„±
        output_file = analyzer.generate_comprehensive_report()
        
        # 6. ì—‘ì…€ íŒŒì¼ ìë™ ì—´ê¸°
        try:
            os.startfile(output_file)
            print(f"\nğŸ”“ ì—‘ì…€ íŒŒì¼ì„ ìë™ìœ¼ë¡œ ì—´ì—ˆìŠµë‹ˆë‹¤.")
        except:
            print(f"\nğŸ’¡ ì—‘ì…€ íŒŒì¼ì„ ìˆ˜ë™ìœ¼ë¡œ ì—´ì–´ì£¼ì„¸ìš”: {output_file}")
        
        print(f"\nğŸ“‹ ìƒì„±ëœ ì‹œíŠ¸ ëª©ë¡:")
        print("  - ì „ì²´_Case_ë¦¬ë“œíƒ€ì„: ëª¨ë“  Case (ì¶œê³ ì™„ë£Œ/ë¯¸ì¶œê³ /ë¯¸ì…ê³  í¬í•¨)")
        print("  - ì¶œê³ ì™„ë£Œ_Case: ì¶œê³ ì™„ë£Œëœ Caseë§Œ")
        print("  - ë¯¸ì¶œê³ _Case: ì•„ì§ ì¶œê³ ë˜ì§€ ì•Šì€ Case")
        print("  - ë¯¸ì…ê³ _Case: ì…ê³ ë˜ì§€ ì•Šì€ Case")
        print("  - ì°½ê³ ë³„_ë¦¬ë“œíƒ€ì„_í†µê³„: ì°½ê³ ë³„ í‰ê· /ì¤‘ì•™ê°’/ìµœëŒ“ê°’")
        print("  - DeadStock_90ì¼+: 90ì¼ ì´ìƒ ì²´ë¥˜ ë¯¸ì¶œê³  Case")
        print("  - ê¸´ë¦¬ë“œíƒ€ì„_90ì¼+: 90ì¼ ì´ìƒ ë¦¬ë“œíƒ€ì„ Case")
        print("  - ì¢…í•©_ë¶„ì„_ìš”ì•½: ì „ì²´ ë¶„ì„ ìš”ì•½ ì •ë³´")
        
        return output_file
        
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback
        traceback.print_exc()
        return None

if __name__ == "__main__":
    main() 