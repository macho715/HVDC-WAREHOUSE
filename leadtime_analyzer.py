#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
HVDC Warehouse ë¦¬ë“œíƒ€ì„ ë¶„ì„ ì‹œìŠ¤í…œ
- Caseë³„ ì…ê³ ì¼ë¶€í„° ì¶œê³ ì¼ê¹Œì§€ì˜ ë¦¬ë“œíƒ€ì„ ê³„ì‚°
- ì°½ê³ ë³„/ìì¬êµ°ë³„ ë¦¬ë“œíƒ€ì„ í†µê³„ ë¶„ì„
- í‰ê· /ì¤‘ì•™ê°’/ìµœëŒ“ê°’ ë“± í†µê³„ ì‚°ì¶œ
"""

import os
import sys
import pandas as pd
import numpy as np
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# scripts í´ë”ì˜ ëª¨ë“ˆë“¤ì„ importí•˜ê¸° ìœ„í•œ ê²½ë¡œ ì„¤ì •
sys.path.append(os.path.join(os.path.dirname(__file__), 'scripts'))

class LeadtimeAnalyzer:
    """ë¦¬ë“œíƒ€ì„ ë¶„ì„ í´ë˜ìŠ¤"""
    
    def __init__(self, excel_path, sheet_name='CASE LIST'):
        """
        ë¦¬ë“œíƒ€ì„ ë¶„ì„ê¸° ì´ˆê¸°í™”
        
        Args:
            excel_path: ì—‘ì…€ íŒŒì¼ ê²½ë¡œ
            sheet_name: ì‹œíŠ¸ ì´ë¦„
        """
        self.excel_path = excel_path
        self.sheet_name = sheet_name
        self.df = None
        self.warehouse_cols = []
        self.site_cols = []
        
        self._load_data()
        self._identify_columns()
    
    def _load_data(self):
        """ë°ì´í„° ë¡œë“œ"""
        print(f"ğŸ“ ë°ì´í„° íŒŒì¼ ë¡œë“œ ì¤‘: {self.excel_path}")
        self.df = pd.read_excel(self.excel_path, sheet_name=self.sheet_name)
        print(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(self.df)}í–‰")
    
    def _identify_columns(self):
        """ì…ê³ /ì¶œê³  ì»¬ëŸ¼ ì‹ë³„"""
        # ì…ê³  ì»¬ëŸ¼ (ì°½ê³ ) ì‹ë³„
        warehouse_patterns = ['DSV', 'Hauler', 'MOSB']
        self.warehouse_cols = []
        for col in self.df.columns:
            if any(pattern in str(col) for pattern in warehouse_patterns):
                self.warehouse_cols.append(col)
        
        # ì¶œê³  ì»¬ëŸ¼ (í˜„ì¥) ì‹ë³„
        site_patterns = ['MIR', 'SHU', 'DAS', 'AGI']
        self.site_cols = []
        for col in self.df.columns:
            if any(pattern in str(col) for pattern in site_patterns):
                self.site_cols.append(col)
        
        print(f"ğŸ­ ì…ê³  ì»¬ëŸ¼ ({len(self.warehouse_cols)}ê°œ): {self.warehouse_cols}")
        print(f"ğŸ—ï¸  ì¶œê³  ì»¬ëŸ¼ ({len(self.site_cols)}ê°œ): {self.site_cols}")
    
    def calculate_leadtime(self):
        """
        ë¦¬ë“œíƒ€ì„ ê³„ì‚°
        
        Returns:
            DataFrame: ë¦¬ë“œíƒ€ì„ì´ ê³„ì‚°ëœ DataFrame
        """
        print("\nğŸ“Š ë¦¬ë“œíƒ€ì„ ê³„ì‚° ì¤‘...")
        
        # 1) ë‚ ì§œ ì»¬ëŸ¼ë“¤ì„ datetimeìœ¼ë¡œ ë³€í™˜
        date_cols = self.warehouse_cols + self.site_cols
        for col in date_cols:
            if col in self.df.columns:
                self.df[col] = pd.to_datetime(self.df[col], errors='coerce')
        
        # 2) ì…ê³ ì¼ ê³„ì‚° (ê° Caseì˜ ëª¨ë“  ì…ê³  ì°½ê³  ì¼ì ì¤‘ ê°€ì¥ ì´ë¥¸ ë‚ ì§œ)
        print("  ğŸ“… ì…ê³ ì¼ ê³„ì‚° ì¤‘...")
        self.df['ì…ê³ ì¼'] = self.df[self.warehouse_cols].min(axis=1)
        
        # 3) ì¶œê³ ì¼ ê³„ì‚° (ê° Caseì˜ ëª¨ë“  ì¶œê³  í˜„ì¥ ì¼ì ì¤‘ ê°€ì¥ ëŠ¦ì€ ë‚ ì§œ)
        print("  ğŸ“… ì¶œê³ ì¼ ê³„ì‚° ì¤‘...")
        self.df['ì¶œê³ ì¼'] = self.df[self.site_cols].max(axis=1)
        
        # 4) ë¦¬ë“œíƒ€ì„(ì¼) ê³„ì‚°
        print("  â±ï¸  ë¦¬ë“œíƒ€ì„ ê³„ì‚° ì¤‘...")
        self.df['ë¦¬ë“œíƒ€ì„(ì¼)'] = (self.df['ì¶œê³ ì¼'] - self.df['ì…ê³ ì¼']).dt.days
        
        # 5) ì´ˆê¸° ì…ê³  ì°½ê³ ëª… ì‹ë³„ (ìµœì´ˆ ì…ê³ ì¼ì„ ì œê³µí•œ ì°½ê³ )
        print("  ğŸ­ ì´ˆê¸° ì…ê³  ì°½ê³  ì‹ë³„ ì¤‘...")
        # ì•ˆì „í•œ ì´ˆê¸° ì°½ê³  ì‹ë³„
        self.df['ì´ˆê¸°ì°½ê³ '] = None
        for idx, row in self.df.iterrows():
            warehouse_dates = row[self.warehouse_cols]
            valid_dates = warehouse_dates.dropna()
            if len(valid_dates) > 0:
                min_date_idx = valid_dates.idxmin()
                self.df.at[idx, 'ì´ˆê¸°ì°½ê³ '] = min_date_idx
        
        # 6) ìœ íš¨í•œ ë¦¬ë“œíƒ€ì„ë§Œ í•„í„°ë§ (ì…ê³ ì¼ê³¼ ì¶œê³ ì¼ì´ ëª¨ë‘ ìˆëŠ” ê²½ìš°)
        valid_mask = self.df['ì…ê³ ì¼'].notna() & self.df['ì¶œê³ ì¼'].notna()
        self.df_valid = self.df[valid_mask].copy()
        
        print(f"âœ… ë¦¬ë“œíƒ€ì„ ê³„ì‚° ì™„ë£Œ!")
        print(f"  ğŸ“Š ì´ Case ìˆ˜: {len(self.df)}")
        print(f"  ğŸ“Š ìœ íš¨í•œ Case ìˆ˜: {len(self.df_valid)}")
        
        if len(self.df_valid) > 0:
            print(f"  ğŸ“Š ë¦¬ë“œíƒ€ì„ í‰ê· : {self.df_valid['ë¦¬ë“œíƒ€ì„(ì¼)'].mean():.1f}ì¼")
            print(f"  ğŸ“Š ë¦¬ë“œíƒ€ì„ ì¤‘ì•™ê°’: {self.df_valid['ë¦¬ë“œíƒ€ì„(ì¼)'].median():.1f}ì¼")
            print(f"  ğŸ“Š ë¦¬ë“œíƒ€ì„ ìµœëŒ“ê°’: {self.df_valid['ë¦¬ë“œíƒ€ì„(ì¼)'].max():.0f}ì¼")
        else:
            print("  âš ï¸  ìœ íš¨í•œ ë¦¬ë“œíƒ€ì„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        return self.df_valid
    
    def analyze_by_warehouse(self):
        """
        ì°½ê³ ë³„ ë¦¬ë“œíƒ€ì„ í†µê³„ ë¶„ì„
        
        Returns:
            DataFrame: ì°½ê³ ë³„ ë¦¬ë“œíƒ€ì„ í†µê³„
        """
        print("\nğŸ­ ì°½ê³ ë³„ ë¦¬ë“œíƒ€ì„ ë¶„ì„ ì¤‘...")
        
        if 'Material Category' in self.df_valid.columns:
            # ìì¬êµ°ë³„ë¡œë„ ê·¸ë£¹í™”
            warehouse_stats = self.df_valid.groupby(['ì´ˆê¸°ì°½ê³ ', 'Material Category'])['ë¦¬ë“œíƒ€ì„(ì¼)'].agg([
                'count', 'mean', 'median', 'std', 'min', 'max'
            ]).reset_index()
            warehouse_stats.columns = ['ì°½ê³ ', 'ìì¬êµ°', 'ê±´ìˆ˜', 'í‰ê· (ì¼)', 'ì¤‘ì•™ê°’(ì¼)', 'í‘œì¤€í¸ì°¨', 'ìµœì†Ÿê°’(ì¼)', 'ìµœëŒ“ê°’(ì¼)']
        else:
            # ì°½ê³ ë³„ë¡œë§Œ ê·¸ë£¹í™”
            warehouse_stats = self.df_valid.groupby('ì´ˆê¸°ì°½ê³ ')['ë¦¬ë“œíƒ€ì„(ì¼)'].agg([
                'count', 'mean', 'median', 'std', 'min', 'max'
            ]).reset_index()
            warehouse_stats.columns = ['ì°½ê³ ', 'ê±´ìˆ˜', 'í‰ê· (ì¼)', 'ì¤‘ì•™ê°’(ì¼)', 'í‘œì¤€í¸ì°¨', 'ìµœì†Ÿê°’(ì¼)', 'ìµœëŒ“ê°’(ì¼)']
        
        # ì†Œìˆ˜ì  ì •ë¦¬
        numeric_cols = warehouse_stats.select_dtypes(include=[np.number]).columns
        warehouse_stats[numeric_cols] = warehouse_stats[numeric_cols].round(1)
        
        print(f"âœ… ì°½ê³ ë³„ ë¶„ì„ ì™„ë£Œ: {len(warehouse_stats)}ê°œ ê·¸ë£¹")
        return warehouse_stats
    
    def analyze_by_material(self):
        """
        ìì¬êµ°ë³„ ë¦¬ë“œíƒ€ì„ í†µê³„ ë¶„ì„
        
        Returns:
            DataFrame: ìì¬êµ°ë³„ ë¦¬ë“œíƒ€ì„ í†µê³„
        """
        if 'Material Category' not in self.df_valid.columns:
            print("âš ï¸  Material Category ì»¬ëŸ¼ì´ ì—†ì–´ ìì¬êµ°ë³„ ë¶„ì„ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            return None
        
        print("\nğŸ“¦ ìì¬êµ°ë³„ ë¦¬ë“œíƒ€ì„ ë¶„ì„ ì¤‘...")
        
        material_stats = self.df_valid.groupby('Material Category')['ë¦¬ë“œíƒ€ì„(ì¼)'].agg([
            'count', 'mean', 'median', 'std', 'min', 'max'
        ]).reset_index()
        material_stats.columns = ['ìì¬êµ°', 'ê±´ìˆ˜', 'í‰ê· (ì¼)', 'ì¤‘ì•™ê°’(ì¼)', 'í‘œì¤€í¸ì°¨', 'ìµœì†Ÿê°’(ì¼)', 'ìµœëŒ“ê°’(ì¼)']
        
        # ì†Œìˆ˜ì  ì •ë¦¬
        numeric_cols = material_stats.select_dtypes(include=[np.number]).columns
        material_stats[numeric_cols] = material_stats[numeric_cols].round(1)
        
        print(f"âœ… ìì¬êµ°ë³„ ë¶„ì„ ì™„ë£Œ: {len(material_stats)}ê°œ ê·¸ë£¹")
        return material_stats
    
    def get_long_leadtime_cases(self, threshold_days=90):
        """
        ê¸´ ë¦¬ë“œíƒ€ì„ Case ëª©ë¡ ì¡°íšŒ
        
        Args:
            threshold_days: ì„ê³„ê°’ (ì¼)
            
        Returns:
            DataFrame: ê¸´ ë¦¬ë“œíƒ€ì„ Case ëª©ë¡
        """
        print(f"\nâ° ê¸´ ë¦¬ë“œíƒ€ì„ Case ë¶„ì„ (ì„ê³„ê°’: {threshold_days}ì¼)...")
        
        long_leadtime = self.df_valid[self.df_valid['ë¦¬ë“œíƒ€ì„(ì¼)'] >= threshold_days].copy()
        long_leadtime = long_leadtime.sort_values('ë¦¬ë“œíƒ€ì„(ì¼)', ascending=False)
        
        print(f"âœ… ê¸´ ë¦¬ë“œíƒ€ì„ Case: {len(long_leadtime)}ê±´")
        return long_leadtime
    
    def generate_report(self, output_file=None):
        """
        ë¦¬ë“œíƒ€ì„ ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±
        
        Args:
            output_file: ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
            
        Returns:
            str: ìƒì„±ëœ íŒŒì¼ ê²½ë¡œ
        """
        print("\nğŸ“‹ ë¦¬ë“œíƒ€ì„ ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„± ì¤‘...")
        
        if output_file is None:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            output_dir = os.path.join(os.path.dirname(__file__), 'outputs')
            os.makedirs(output_dir, exist_ok=True)
            output_file = os.path.join(output_dir, f'ë¦¬ë“œíƒ€ì„_ë¶„ì„_{timestamp}.xlsx')
        
        with pd.ExcelWriter(output_file, engine='openpyxl') as writer:
            # 1. ì „ì²´ Case ë¦¬ë“œíƒ€ì„ ë°ì´í„°
            print("  ğŸ“‹ ì „ì²´ Case ë¦¬ë“œíƒ€ì„ ë°ì´í„° ì €ì¥ ì¤‘...")
            self.df_valid.to_excel(writer, sheet_name='ì „ì²´_Case_ë¦¬ë“œíƒ€ì„', index=False)
            
            # 2. ì°½ê³ ë³„ í†µê³„
            print("  ğŸ“‹ ì°½ê³ ë³„ í†µê³„ ì €ì¥ ì¤‘...")
            warehouse_stats = self.analyze_by_warehouse()
            warehouse_stats.to_excel(writer, sheet_name='ì°½ê³ ë³„_ë¦¬ë“œíƒ€ì„_í†µê³„', index=False)
            
            # 3. ìì¬êµ°ë³„ í†µê³„
            print("  ğŸ“‹ ìì¬êµ°ë³„ í†µê³„ ì €ì¥ ì¤‘...")
            material_stats = self.analyze_by_material()
            if material_stats is not None:
                material_stats.to_excel(writer, sheet_name='ìì¬êµ°ë³„_ë¦¬ë“œíƒ€ì„_í†µê³„', index=False)
            
            # 4. ê¸´ ë¦¬ë“œíƒ€ì„ Case ëª©ë¡
            print("  ğŸ“‹ ê¸´ ë¦¬ë“œíƒ€ì„ Case ëª©ë¡ ì €ì¥ ì¤‘...")
            long_leadtime = self.get_long_leadtime_cases(90)
            long_leadtime.to_excel(writer, sheet_name='ê¸´ë¦¬ë“œíƒ€ì„_90ì¼+', index=False)
            
            # 5. ìš”ì•½ ì •ë³´
            print("  ğŸ“‹ ìš”ì•½ ì •ë³´ ì €ì¥ ì¤‘...")
            summary_data = {
                'ë¶„ì„ í•­ëª©': [
                    'ì´ Case ìˆ˜',
                    'ìœ íš¨í•œ Case ìˆ˜',
                    'í‰ê·  ë¦¬ë“œíƒ€ì„(ì¼)',
                    'ì¤‘ì•™ê°’ ë¦¬ë“œíƒ€ì„(ì¼)',
                    'ìµœëŒ“ê°’ ë¦¬ë“œíƒ€ì„(ì¼)',
                    '90ì¼ ì´ìƒ ë¦¬ë“œíƒ€ì„ Case ìˆ˜',
                    'ë¶„ì„ ì°½ê³  ìˆ˜',
                    'ë¶„ì„ ìì¬êµ° ìˆ˜'
                ],
                'ê°’': [
                    len(self.df),
                    len(self.df_valid),
                    round(self.df_valid['ë¦¬ë“œíƒ€ì„(ì¼)'].mean(), 1),
                    round(self.df_valid['ë¦¬ë“œíƒ€ì„(ì¼)'].median(), 1),
                    self.df_valid['ë¦¬ë“œíƒ€ì„(ì¼)'].max(),
                    len(self.get_long_leadtime_cases(90)),
                    len(self.df_valid['ì´ˆê¸°ì°½ê³ '].unique()),
                    len(self.df_valid['Material Category'].unique()) if 'Material Category' in self.df_valid.columns else 0
                ]
            }
            summary_df = pd.DataFrame(summary_data)
            summary_df.to_excel(writer, sheet_name='ë¶„ì„_ìš”ì•½', index=False)
        
        print(f"âœ… ë¦¬ë“œíƒ€ì„ ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ!")
        print(f"ğŸ“„ íŒŒì¼ëª…: {os.path.basename(output_file)}")
        print(f"ğŸ“„ íŒŒì¼ í¬ê¸°: {os.path.getsize(output_file) / 1024:.1f} KB")
        
        return output_file

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("=== HVDC Warehouse ë¦¬ë“œíƒ€ì„ ë¶„ì„ ì‹œìŠ¤í…œ ===")
    print(f"ì‹¤í–‰ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # 1. ë°ì´í„° íŒŒì¼ ê²½ë¡œ ì„¤ì •
    current_dir = os.path.dirname(os.path.abspath(__file__))
    excel_path = os.path.join(current_dir, 'data', 'HVDC WAREHOUSE_HITACHI(HE).xlsx')
    
    if not os.path.exists(excel_path):
        print(f"âŒ ì˜¤ë¥˜: ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {excel_path}")
        return
    
    try:
        # 2. ë¦¬ë“œíƒ€ì„ ë¶„ì„ê¸° ì´ˆê¸°í™”
        print(f"\nğŸ“ ë°ì´í„° íŒŒì¼: {excel_path}")
        analyzer = LeadtimeAnalyzer(excel_path, sheet_name='CASE LIST')
        
        # 3. ë¦¬ë“œíƒ€ì„ ê³„ì‚°
        df_valid = analyzer.calculate_leadtime()
        
        # 4. ìƒì„¸ ë¶„ì„
        print("\nğŸ“Š ìƒì„¸ ë¶„ì„ ê²°ê³¼:")
        
        # ì°½ê³ ë³„ ë¶„ì„
        warehouse_stats = analyzer.analyze_by_warehouse()
        print(f"\nğŸ­ ì°½ê³ ë³„ ë¦¬ë“œíƒ€ì„ í†µê³„:")
        print(warehouse_stats.to_string(index=False))
        
        # ìì¬êµ°ë³„ ë¶„ì„
        material_stats = analyzer.analyze_by_material()
        if material_stats is not None:
            print(f"\nğŸ“¦ ìì¬êµ°ë³„ ë¦¬ë“œíƒ€ì„ í†µê³„:")
            print(material_stats.to_string(index=False))
        
        # ê¸´ ë¦¬ë“œíƒ€ì„ Case ë¶„ì„
        long_leadtime = analyzer.get_long_leadtime_cases(90)
        print(f"\nâ° 90ì¼ ì´ìƒ ë¦¬ë“œíƒ€ì„ Case (ìƒìœ„ 10ê±´):")
        if len(long_leadtime) > 0:
            display_cols = ['Case No.', 'ì´ˆê¸°ì°½ê³ ', 'ì…ê³ ì¼', 'ì¶œê³ ì¼', 'ë¦¬ë“œíƒ€ì„(ì¼)']
            if 'Material Category' in long_leadtime.columns:
                display_cols.insert(2, 'Material Category')
            
            print(long_leadtime[display_cols].head(10).to_string(index=False))
        
        # 5. ì—‘ì…€ ë¦¬í¬íŠ¸ ìƒì„±
        output_file = analyzer.generate_report()
        
        # 6. ì—‘ì…€ íŒŒì¼ ìë™ ì—´ê¸°
        try:
            os.startfile(output_file)
            print(f"\nğŸ”“ ì—‘ì…€ íŒŒì¼ì„ ìë™ìœ¼ë¡œ ì—´ì—ˆìŠµë‹ˆë‹¤.")
        except:
            print(f"\nğŸ’¡ ì—‘ì…€ íŒŒì¼ì„ ìˆ˜ë™ìœ¼ë¡œ ì—´ì–´ì£¼ì„¸ìš”: {output_file}")
        
        print(f"\nğŸ“‹ ìƒì„±ëœ ì‹œíŠ¸ ëª©ë¡:")
        print("  - ì „ì²´_Case_ë¦¬ë“œíƒ€ì„: ëª¨ë“  Caseì˜ ë¦¬ë“œíƒ€ì„ ë°ì´í„°")
        print("  - ì°½ê³ ë³„_ë¦¬ë“œíƒ€ì„_í†µê³„: ì°½ê³ ë³„ í‰ê· /ì¤‘ì•™ê°’/ìµœëŒ“ê°’")
        print("  - ìì¬êµ°ë³„_ë¦¬ë“œíƒ€ì„_í†µê³„: ìì¬êµ°ë³„ í†µê³„ (Material Category ì»¬ëŸ¼ì´ ìˆëŠ” ê²½ìš°)")
        print("  - ê¸´ë¦¬ë“œíƒ€ì„_90ì¼+: 90ì¼ ì´ìƒ ë¦¬ë“œíƒ€ì„ Case ëª©ë¡")
        print("  - ë¶„ì„_ìš”ì•½: ì „ì²´ ë¶„ì„ ìš”ì•½ ì •ë³´")
        
        return output_file
        
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback
        traceback.print_exc()
        return None

if __name__ == "__main__":
    main() 